{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Agent for Pac Man game\n",
    "We create a simple neural network agent for Pac Man game. We first initiate a set of random weights and bias and let it play, and choose the agent with the longest time.\n",
    "\n",
    "Here, the agents don't learn any policy, but relies on initial parameters to make actions(i.e. fixed policy). We use fully connected layers for this problem. The Pac Man has 9 actions -- wait, turn right, turn left, turn up, turn down, go left, go right, go up, go down. So in total, we have 9 output neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class called RlAgent\n",
    "class RlAgent:\n",
    "    def __init__(self,m,n,ini=False,W=None,b=None):\n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            self._X = tf.placeholder(tf.float32,shape=(1,m))\n",
    "            if ini == False:\n",
    "                self.W = tf.Variable(tf.random_normal([m,n]),dtype=tf.float32,trainable=False)\n",
    "                self.bias = tf.Variable(tf.random_normal([1,n]),dtype=tf.float32,trainable=False)\n",
    "            else:\n",
    "                self.W = W.astype(np.float32)\n",
    "                self.bias = b.astype(np.float32)\n",
    "            out = tf.nn.sigmoid(tf.matmul(self._X,self.W)+self.bias)\n",
    "            self._result = tf.multinomial(out,1)\n",
    "            init = tf.global_variables_initializer()\n",
    "            self._sess = tf.Session()\n",
    "            self._sess.run(init)\n",
    "    def predict(self,X):\n",
    "        action = self._sess.run(self._result,feed_dict={self._X:X})\n",
    "        return action\n",
    "    def get_weights(self):\n",
    "        W, b = self._sess.run([self.W,self.bias])\n",
    "        return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every step the enviroment will return an observation\n",
    "# with 3 color channels, we preprocess the image by turning it \n",
    "# to grey scales and bring better contrast\n",
    "def preprocess_image(img):\n",
    "    img = img.mean(axis = 2) # to grayscale\n",
    "    img[img==150] = 0 # bring about a better contrast\n",
    "    img = (img-128)/128 - 1 # Normalize image from -1 to 1\n",
    "    m,n = img.shape\n",
    "    return img.reshape(1,m*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function play_one_episode to play a game\n",
    "def play_one_episode(env,agent,show=False):\n",
    "    obs = env.reset()\n",
    "    img_pre = preprocess_image(obs)\n",
    "    done = False\n",
    "    t = 0\n",
    "    while not done and t < 10000:\n",
    "        if show == True:\n",
    "            env.render()\n",
    "            time.sleep(0.3)\n",
    "        t += 1\n",
    "        action = agent.predict(img_pre)\n",
    "#         print(action)\n",
    "#         print(t,action)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        img_pre = preprocess_image(obs)\n",
    "        if done:\n",
    "            break\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an agent with the function play_multiple_episodes,\n",
    "# let the agent play the game for multiple times and return \n",
    "# the average time\n",
    "def play_multiple_episodes(env, T, ini=False, W=None, b=None):\n",
    "    episode_lengths = np.empty(T)\n",
    "    obs = env.reset()\n",
    "    img_pre = preprocess_image(obs)\n",
    "    if ini == False:\n",
    "        agent = RlAgent(img_pre.shape[1],env.action_space.n)\n",
    "    else:\n",
    "        agent = RlAgent(img_pre.shape[1],env.action_space.n,ini,W,b)\n",
    "    for i in range(T):\n",
    "        episode_lengths[i] = play_one_episode(env,agent)\n",
    "    avg_length = episode_lengths.mean()\n",
    "    print('avg length:',avg_length)\n",
    "    if ini == False:\n",
    "        W, b = agent.get_weights()\n",
    "    return avg_length, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search will call play_multiple_episodes, it will create\n",
    "# agents with random weights and bias every time, and choose the \n",
    "# best one as the winner\n",
    "def random_search(env):\n",
    "    episode_lengths = []\n",
    "    best = 0\n",
    "    for t in range(1):\n",
    "        print('Agent {} reporting'.format(t))\n",
    "        avg_length, wts, bias = play_multiple_episodes(env,10)\n",
    "        episode_lengths.append(avg_length)\n",
    "        if avg_length > best:\n",
    "            best_wt = wts\n",
    "            best_bias = bias\n",
    "            best = avg_length\n",
    "    return episode_lengths, best_wt, best_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 0 reporting\n",
      "avg length: 298.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Run with Best Agent\n",
      "avg length: 217.4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'img_pre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-2ce780dd215a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# print(W,b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplay_multiple_episodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mini\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRlAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mini\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplay_one_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_pre' is not defined"
     ]
    }
   ],
   "source": [
    "env_name = 'Breakout-v0'\n",
    "# env_name = 'MsPacman-v0'\n",
    "env = gym.make(env_name)\n",
    "episode_lengths, W, b = random_search(env)\n",
    "plt.plot(episode_lengths)\n",
    "plt.show()\n",
    "print('Final Run with Best Agent')\n",
    "# print(W.shape,b.shape)\n",
    "# print(W,b)\n",
    "play_multiple_episodes(env,10, ini=True,W=W,b=b)\n",
    "\n",
    "obs = env.reset()\n",
    "img_pre = preprocess_image(obs)\n",
    "agent = RlAgent(img_pre.shape[1],env.action_space.n,ini,W,b)\n",
    "play_one_episode(env,agent,show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
