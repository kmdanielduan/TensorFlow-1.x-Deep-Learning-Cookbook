{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient for Pong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym \n",
    "from gym import wrappers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(object):\n",
    "    def __init__(self, N_SIZE, h=200, gamma=0.99, eta=1e-3,decay=0.99, save_path = 'models2/pong.ckpt'):\n",
    "        self.gamma = gamma\n",
    "        self.save_path = save_path\n",
    "        # Placeholders for passing state ...\n",
    "        self.tf_x = tf.placeholder(dtype=tf.float32, shape=[None, N_SIZE*N_SIZE], name = \"tf_x\")\n",
    "        self.tf_y = tf.placeholder(dtype=tf.float32, shape=[None, n_actions], name = \"tf_y\")\n",
    "        self.tf_epr = tf.placeholder(dtype=tf.float32, shape=[None, 1], name = \"tf_epr\")\n",
    "        \n",
    "        # Weights\n",
    "        xavier_l1 = tf.truncated_normal_initializer(mean=0,stddev=1. / N_SIZE, dtype=tf.float32)\n",
    "        self.W1 = tf.get_variable(\"W1\", [N_SIZE * N_SIZE, h], initializer=xavier_l1)\n",
    "        xavier_l2 = tf.truncated_normal_initializer(mean=0,stddev=1. / np.sqrt(h), dtype=tf.float32)\n",
    "        self.W2 = tf.get_variable(\"W2\", [h, n_actions], initializer=xavier_l2)\n",
    "        \n",
    "        # Build Computation\n",
    "        # tf reward processing (need tf_discounted_epr for policy gradient wizardry)\n",
    "        tf_discounted_epr = self.tf_discount_rewards(self.tf_epr)\n",
    "        tf_mean, tf_variance = tf.nn.moments(tf_discounted_epr, [0], shift=None, name=\"reward_moments\")\n",
    "        tf_discounted_epr -= tf_mean\n",
    "        tf_discounted_epr /= tf.sqrt(tf_variance + 1e-6)\n",
    "        \n",
    "        # Define Optimizer, compute and apply gradients\n",
    "        self.tf_aprob = self.tf_policy_forward(self.tf_x)\n",
    "        loss = tf.nn.l2_loss(self.tf_y - self.tf_aprob)\n",
    "        optimizer = tf.train.RMSPropOptimizer(eta, decay=decay)\n",
    "        tf_grads = optimizer.compute_gradients(loss, var_list=tf.trainable_variables(), grad_loss=tf_discounted_epr)\n",
    "        self.train_op = optimizer.apply_gradients(tf_grads)\n",
    "        \n",
    "        # Initialize Variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.session = tf.InteractiveSession()\n",
    "        self.session.run(init)\n",
    "        self.load()\n",
    "        \n",
    "    def tf_discount_rewards(self, tf_r): # tf_r ~ [game_steps, 1]\n",
    "        discount_f = lambda a, v: a * self.gamma + v\n",
    "        tf_r_reverse = tf.scan(discount_f, tf.reverse(tf_r,[0]))\n",
    "        tf_discounted_r = tf.reverse(tf_r_reverse, [0])\n",
    "        return tf_discounted_r\n",
    "    \n",
    "    def tf_policy_forward(self, x): #x ~ [1,D]\n",
    "        h = tf.matmul(x, self.W1)\n",
    "        h = tf.nn.relu(h)\n",
    "        logp = tf.matmul(h, self.W2)\n",
    "        p = tf.nn.softmax(logp)\n",
    "        return p\n",
    "    \n",
    "    def predict_UP(self,x):\n",
    "        feed = {self.tf_x: np.reshape(x, (1,-1))}\n",
    "        aprob = self.session.run(self.tf_aprob, feed)\n",
    "        return aprob\n",
    "    \n",
    "    def update(self, feed):\n",
    "        return self.session.run(self.train_op, feed)\n",
    "    \n",
    "    def load(self):\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "        load_was_success = True \n",
    "        try:\n",
    "            save_dir = '/'.join(self.save_path.split('/')[:-1])\n",
    "            ckpt = tf.train.get_checkpoint_state(Svae_dir)\n",
    "            load_path = ckpt.model_checkpoint_path\n",
    "            self.saver.restore(self.session, load_path)\n",
    "        except:\n",
    "            print(\"no saved model to load. starting new session\")\n",
    "            load_was_success = False\n",
    "        else:\n",
    "            print(\"loaded model: {}\".format(load_path))\n",
    "            saver = tf.train.Saver(tf.global_variables())\n",
    "            episode_number = int(load_path.split('-')[-1])\n",
    "    \n",
    "    def save(self):\n",
    "        self.saver.save(self.session, self.save_path, global_step=n)\n",
    "        print(\"SAVED MODEL #{}\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsampling\n",
    "def preprocess(I):\n",
    "    \"\"\"prepro 210*160*3 uint8 frame into 80*80 1D float vector\"\"\"\n",
    "    I = I[35:195] # crop\n",
    "    I = I [::2,::2,0] # downsample by factor of 2\n",
    "    I[I == 144] = 0 # erase background type 1\n",
    "    I[I == 109] = 0 # erase background type 2\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return I.astype(np.float).ravel()\n",
    "\n",
    "# testing for the above function\n",
    "def test_preprocess():\n",
    "    env = gym.make(\"Pong-v0\")\n",
    "    observation = env.reset()\n",
    "    img = preprocess(observation)\n",
    "\n",
    "    plt.imshow(observation)\n",
    "    plt.show()\n",
    "    print(observation.shape)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print(img.shape)\n",
    "    env.close()\n",
    "\n",
    "# test_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Game Environment\n",
    "env_name = \"Pong-v0\"\n",
    "env = gym.make(env_name)\n",
    "env = wrappers.Monitor(env, 'tmp/pong', force=True)\n",
    "n_actions = env.action_space.n # number of possible actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "no saved model to load. starting new session\n"
     ]
    }
   ],
   "source": [
    "# Initializing Game and State(t-1), action, reward, state(t)\n",
    "xs, rs, ys = [], [], []\n",
    "obs = env.reset()\n",
    "prev_x = None\n",
    "\n",
    "running_reward = None\n",
    "running_rewards = []\n",
    "reward_sum = 0\n",
    "n = 0\n",
    "done= False\n",
    "n_size = 80\n",
    "num_episodes = 500\n",
    "\n",
    "# Create agent\n",
    "agent = PolicyNetwork(n_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: reward: -19.0, mean reward: -19.000000\n",
      "\tep 1: reward: -20.0\n",
      "\tep 2: reward: -21.0\n",
      "\tep 3: reward: -20.0\n",
      "\tep 4: reward: -19.0\n",
      "\tep 5: reward: -20.0\n",
      "\tep 6: reward: -21.0\n",
      "\tep 7: reward: -20.0\n",
      "\tep 8: reward: -21.0\n",
      "\tep 9: reward: -20.0\n",
      "ep 10: reward: -21.0, mean reward: -19.124838\n",
      "\tep 11: reward: -20.0\n",
      "\tep 12: reward: -19.0\n",
      "\tep 13: reward: -20.0\n",
      "\tep 14: reward: -20.0\n",
      "\tep 15: reward: -21.0\n",
      "\tep 16: reward: -21.0\n",
      "\tep 17: reward: -19.0\n",
      "\tep 18: reward: -21.0\n",
      "\tep 19: reward: -21.0\n",
      "ep 20: reward: -21.0, mean reward: -19.238405\n",
      "\tep 21: reward: -21.0\n",
      "\tep 22: reward: -20.0\n",
      "\tep 23: reward: -21.0\n",
      "\tep 24: reward: -21.0\n",
      "\tep 25: reward: -21.0\n",
      "\tep 26: reward: -20.0\n",
      "\tep 27: reward: -21.0\n",
      "\tep 28: reward: -21.0\n",
      "\tep 29: reward: -20.0\n",
      "ep 30: reward: -21.0, mean reward: -19.378112\n",
      "\tep 31: reward: -20.0\n",
      "\tep 32: reward: -20.0\n",
      "\tep 33: reward: -20.0\n",
      "\tep 34: reward: -18.0\n",
      "\tep 35: reward: -21.0\n",
      "\tep 36: reward: -19.0\n",
      "\tep 37: reward: -21.0\n",
      "\tep 38: reward: -21.0\n",
      "\tep 39: reward: -18.0\n",
      "ep 40: reward: -20.0, mean reward: -19.418354\n",
      "\tep 41: reward: -20.0\n",
      "\tep 42: reward: -19.0\n",
      "\tep 43: reward: -19.0\n",
      "\tep 44: reward: -20.0\n",
      "\tep 45: reward: -20.0\n",
      "\tep 46: reward: -21.0\n",
      "\tep 47: reward: -19.0\n",
      "\tep 48: reward: -20.0\n",
      "\tep 49: reward: -20.0\n",
      "SAVED MODEL #50\n",
      "ep 50: reward: -21.0, mean reward: -19.465324\n",
      "\tep 51: reward: -20.0\n",
      "\tep 52: reward: -21.0\n",
      "\tep 53: reward: -21.0\n",
      "\tep 54: reward: -21.0\n",
      "\tep 55: reward: -19.0\n",
      "\tep 56: reward: -20.0\n",
      "\tep 57: reward: -20.0\n",
      "\tep 58: reward: -19.0\n",
      "\tep 59: reward: -21.0\n",
      "ep 60: reward: -21.0, mean reward: -19.545001\n",
      "\tep 61: reward: -20.0\n",
      "\tep 62: reward: -21.0\n",
      "\tep 63: reward: -19.0\n",
      "\tep 64: reward: -20.0\n",
      "\tep 65: reward: -21.0\n",
      "\tep 66: reward: -20.0\n",
      "\tep 67: reward: -21.0\n",
      "\tep 68: reward: -19.0\n",
      "\tep 69: reward: -21.0\n",
      "ep 70: reward: -20.0, mean reward: -19.607726\n",
      "\tep 71: reward: -20.0\n",
      "\tep 72: reward: -17.0\n",
      "\tep 73: reward: -18.0\n",
      "\tep 74: reward: -20.0\n",
      "\tep 75: reward: -20.0\n",
      "\tep 76: reward: -21.0\n",
      "\tep 77: reward: -20.0\n",
      "\tep 78: reward: -21.0\n",
      "\tep 79: reward: -21.0\n",
      "ep 80: reward: -21.0, mean reward: -19.638218\n",
      "\tep 81: reward: -20.0\n",
      "\tep 82: reward: -21.0\n",
      "\tep 83: reward: -20.0\n",
      "\tep 84: reward: -19.0\n",
      "\tep 85: reward: -20.0\n",
      "\tep 86: reward: -21.0\n",
      "\tep 87: reward: -21.0\n",
      "\tep 88: reward: -20.0\n",
      "\tep 89: reward: -20.0\n",
      "ep 90: reward: -21.0, mean reward: -19.701932\n",
      "\tep 91: reward: -20.0\n",
      "\tep 92: reward: -21.0\n",
      "\tep 93: reward: -19.0\n",
      "\tep 94: reward: -20.0\n",
      "\tep 95: reward: -19.0\n",
      "\tep 96: reward: -20.0\n",
      "\tep 97: reward: -20.0\n",
      "\tep 98: reward: -21.0\n",
      "\tep 99: reward: -20.0\n",
      "SAVED MODEL #100\n",
      "ep 100: reward: -21.0, mean reward: -19.740631\n",
      "\tep 101: reward: -21.0\n",
      "\tep 102: reward: -20.0\n",
      "\tep 103: reward: -20.0\n",
      "\tep 104: reward: -20.0\n",
      "\tep 105: reward: -21.0\n",
      "\tep 106: reward: -20.0\n",
      "\tep 107: reward: -20.0\n",
      "\tep 108: reward: -20.0\n",
      "\tep 109: reward: -20.0\n",
      "ep 110: reward: -20.0, mean reward: -19.784076\n",
      "\tep 111: reward: -21.0\n",
      "\tep 112: reward: -20.0\n",
      "\tep 113: reward: -21.0\n",
      "\tep 114: reward: -20.0\n",
      "\tep 115: reward: -19.0\n",
      "\tep 116: reward: -20.0\n",
      "\tep 117: reward: -20.0\n",
      "\tep 118: reward: -19.0\n",
      "\tep 119: reward: -19.0\n",
      "ep 120: reward: -21.0, mean reward: -19.803967\n",
      "\tep 121: reward: -21.0\n",
      "\tep 122: reward: -21.0\n",
      "\tep 123: reward: -21.0\n",
      "\tep 124: reward: -21.0\n",
      "\tep 125: reward: -19.0\n",
      "\tep 126: reward: -21.0\n",
      "\tep 127: reward: -20.0\n",
      "\tep 128: reward: -21.0\n",
      "\tep 129: reward: -20.0\n",
      "ep 130: reward: -21.0, mean reward: -19.879707\n",
      "\tep 131: reward: -21.0\n",
      "\tep 132: reward: -21.0\n",
      "\tep 133: reward: -18.0\n",
      "\tep 134: reward: -20.0\n",
      "\tep 135: reward: -21.0\n",
      "\tep 136: reward: -21.0\n",
      "\tep 137: reward: -21.0\n",
      "\tep 138: reward: -21.0\n",
      "\tep 139: reward: -17.0\n",
      "ep 140: reward: -19.0, mean reward: -19.889850\n",
      "\tep 141: reward: -21.0\n",
      "\tep 142: reward: -20.0\n",
      "\tep 143: reward: -21.0\n",
      "\tep 144: reward: -20.0\n",
      "\tep 145: reward: -21.0\n",
      "\tep 146: reward: -19.0\n",
      "\tep 147: reward: -21.0\n",
      "\tep 148: reward: -20.0\n",
      "\tep 149: reward: -21.0\n",
      "SAVED MODEL #150\n",
      "ep 150: reward: -20.0, mean reward: -19.938345\n",
      "\tep 151: reward: -19.0\n",
      "\tep 152: reward: -21.0\n",
      "\tep 153: reward: -20.0\n",
      "\tep 154: reward: -20.0\n",
      "\tep 155: reward: -21.0\n",
      "\tep 156: reward: -20.0\n",
      "\tep 157: reward: -19.0\n",
      "\tep 158: reward: -19.0\n",
      "\tep 159: reward: -21.0\n",
      "ep 160: reward: -20.0, mean reward: -19.944238\n",
      "\tep 161: reward: -19.0\n",
      "\tep 162: reward: -21.0\n",
      "\tep 163: reward: -20.0\n",
      "\tep 164: reward: -21.0\n",
      "\tep 165: reward: -20.0\n",
      "\tep 166: reward: -21.0\n",
      "\tep 167: reward: -20.0\n",
      "\tep 168: reward: -20.0\n",
      "\tep 169: reward: -20.0\n",
      "ep 170: reward: -20.0, mean reward: -19.968683\n",
      "\tep 171: reward: -20.0\n",
      "\tep 172: reward: -21.0\n",
      "\tep 173: reward: -20.0\n",
      "\tep 174: reward: -20.0\n",
      "\tep 175: reward: -21.0\n",
      "\tep 176: reward: -20.0\n",
      "\tep 177: reward: -19.0\n",
      "\tep 178: reward: -21.0\n",
      "\tep 179: reward: -21.0\n",
      "ep 180: reward: -21.0, mean reward: -20.010413\n",
      "\tep 181: reward: -21.0\n",
      "\tep 182: reward: -21.0\n",
      "\tep 183: reward: -20.0\n",
      "\tep 184: reward: -20.0\n",
      "\tep 185: reward: -21.0\n",
      "\tep 186: reward: -21.0\n",
      "\tep 187: reward: -21.0\n",
      "\tep 188: reward: -19.0\n",
      "\tep 189: reward: -21.0\n",
      "ep 190: reward: -21.0, mean reward: -20.066698\n",
      "\tep 191: reward: -20.0\n",
      "\tep 192: reward: -21.0\n",
      "\tep 193: reward: -19.0\n",
      "\tep 194: reward: -21.0\n",
      "\tep 195: reward: -21.0\n",
      "\tep 196: reward: -20.0\n",
      "\tep 197: reward: -20.0\n",
      "\tep 198: reward: -21.0\n",
      "\tep 199: reward: -20.0\n",
      "SAVED MODEL #200\n",
      "ep 200: reward: -21.0, mean reward: -20.098953\n",
      "\tep 201: reward: -20.0\n",
      "\tep 202: reward: -21.0\n",
      "\tep 203: reward: -20.0\n",
      "\tep 204: reward: -19.0\n",
      "\tep 205: reward: -21.0\n",
      "\tep 206: reward: -21.0\n",
      "\tep 207: reward: -19.0\n",
      "\tep 208: reward: -21.0\n",
      "\tep 209: reward: -21.0\n",
      "ep 210: reward: -20.0, mean reward: -20.118418\n",
      "\tep 211: reward: -21.0\n",
      "\tep 212: reward: -20.0\n",
      "\tep 213: reward: -21.0\n",
      "\tep 214: reward: -20.0\n",
      "\tep 215: reward: -21.0\n",
      "\tep 216: reward: -20.0\n",
      "\tep 217: reward: -20.0\n",
      "\tep 218: reward: -21.0\n",
      "\tep 219: reward: -20.0\n",
      "ep 220: reward: -20.0, mean reward: -20.144862\n",
      "\tep 221: reward: -21.0\n",
      "\tep 222: reward: -20.0\n",
      "\tep 223: reward: -21.0\n",
      "\tep 224: reward: -21.0\n",
      "\tep 225: reward: -21.0\n",
      "\tep 226: reward: -21.0\n",
      "\tep 227: reward: -20.0\n",
      "\tep 228: reward: -20.0\n",
      "\tep 229: reward: -20.0\n",
      "ep 230: reward: -19.0, mean reward: -20.167997\n",
      "\tep 231: reward: -21.0\n",
      "\tep 232: reward: -20.0\n",
      "\tep 233: reward: -20.0\n",
      "\tep 234: reward: -21.0\n",
      "\tep 235: reward: -18.0\n",
      "\tep 236: reward: -21.0\n",
      "\tep 237: reward: -19.0\n",
      "\tep 238: reward: -18.0\n",
      "\tep 239: reward: -18.0\n",
      "ep 240: reward: -19.0, mean reward: -20.101964\n",
      "\tep 241: reward: -21.0\n",
      "\tep 242: reward: -20.0\n",
      "\tep 243: reward: -21.0\n",
      "\tep 244: reward: -21.0\n",
      "\tep 245: reward: -20.0\n",
      "\tep 246: reward: -21.0\n",
      "\tep 247: reward: -20.0\n",
      "\tep 248: reward: -21.0\n",
      "\tep 249: reward: -18.0\n",
      "SAVED MODEL #250\n",
      "ep 250: reward: -19.0, mean reward: -20.109692\n",
      "\tep 251: reward: -21.0\n",
      "\tep 252: reward: -21.0\n",
      "\tep 253: reward: -21.0\n",
      "\tep 254: reward: -20.0\n",
      "\tep 255: reward: -20.0\n",
      "\tep 256: reward: -21.0\n",
      "\tep 257: reward: -21.0\n",
      "\tep 258: reward: -21.0\n",
      "\tep 259: reward: -21.0\n",
      "ep 260: reward: -19.0, mean reward: -20.155897\n",
      "\tep 261: reward: -21.0\n",
      "\tep 262: reward: -18.0\n",
      "\tep 263: reward: -21.0\n",
      "\tep 264: reward: -20.0\n",
      "\tep 265: reward: -20.0\n",
      "\tep 266: reward: -21.0\n",
      "\tep 267: reward: -21.0\n",
      "\tep 268: reward: -20.0\n",
      "\tep 269: reward: -21.0\n",
      "ep 270: reward: -21.0, mean reward: -20.180200\n",
      "\tep 271: reward: -21.0\n",
      "\tep 272: reward: -20.0\n",
      "\tep 273: reward: -21.0\n",
      "\tep 274: reward: -21.0\n",
      "\tep 275: reward: -20.0\n",
      "\tep 276: reward: -21.0\n",
      "\tep 277: reward: -20.0\n",
      "\tep 278: reward: -21.0\n",
      "\tep 279: reward: -21.0\n",
      "ep 280: reward: -20.0, mean reward: -20.220148\n",
      "\tep 281: reward: -19.0\n",
      "\tep 282: reward: -18.0\n",
      "\tep 283: reward: -21.0\n",
      "\tep 284: reward: -19.0\n",
      "\tep 285: reward: -20.0\n",
      "\tep 286: reward: -21.0\n",
      "\tep 287: reward: -21.0\n",
      "\tep 288: reward: -20.0\n",
      "\tep 289: reward: -20.0\n",
      "ep 290: reward: -21.0, mean reward: -20.200722\n",
      "\tep 291: reward: -21.0\n",
      "\tep 292: reward: -21.0\n",
      "\tep 293: reward: -20.0\n",
      "\tep 294: reward: -20.0\n",
      "\tep 295: reward: -19.0\n",
      "\tep 296: reward: -20.0\n",
      "\tep 297: reward: -19.0\n",
      "\tep 298: reward: -21.0\n",
      "\tep 299: reward: -21.0\n",
      "WARNING:tensorflow:From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "SAVED MODEL #300\n",
      "ep 300: reward: -21.0, mean reward: -20.210380\n",
      "\tep 301: reward: -21.0\n",
      "\tep 302: reward: -20.0\n",
      "\tep 303: reward: -20.0\n",
      "\tep 304: reward: -19.0\n",
      "\tep 305: reward: -18.0\n",
      "\tep 306: reward: -18.0\n",
      "\tep 307: reward: -21.0\n",
      "\tep 308: reward: -19.0\n",
      "\tep 309: reward: -21.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 310: reward: -20.0, mean reward: -20.161555\n",
      "\tep 311: reward: -21.0\n",
      "\tep 312: reward: -19.0\n",
      "\tep 313: reward: -18.0\n",
      "\tep 314: reward: -18.0\n",
      "\tep 315: reward: -21.0\n",
      "\tep 316: reward: -20.0\n",
      "\tep 317: reward: -20.0\n",
      "\tep 318: reward: -18.0\n",
      "\tep 319: reward: -20.0\n",
      "ep 320: reward: -21.0, mean reward: -20.108452\n",
      "\tep 321: reward: -20.0\n",
      "\tep 322: reward: -21.0\n",
      "\tep 323: reward: -21.0\n",
      "\tep 324: reward: -21.0\n",
      "\tep 325: reward: -19.0\n",
      "\tep 326: reward: -21.0\n",
      "\tep 327: reward: -20.0\n",
      "\tep 328: reward: -18.0\n",
      "\tep 329: reward: -21.0\n",
      "ep 330: reward: -21.0, mean reward: -20.126439\n",
      "\tep 331: reward: -21.0\n",
      "\tep 332: reward: -20.0\n",
      "\tep 333: reward: -21.0\n",
      "\tep 334: reward: -21.0\n",
      "\tep 335: reward: -20.0\n",
      "\tep 336: reward: -19.0\n",
      "\tep 337: reward: -20.0\n",
      "\tep 338: reward: -21.0\n",
      "\tep 339: reward: -21.0\n",
      "ep 340: reward: -17.0, mean reward: -20.122315\n",
      "\tep 341: reward: -19.0\n",
      "\tep 342: reward: -21.0\n",
      "\tep 343: reward: -21.0\n",
      "\tep 344: reward: -19.0\n",
      "\tep 345: reward: -21.0\n",
      "\tep 346: reward: -21.0\n",
      "\tep 347: reward: -21.0\n",
      "\tep 348: reward: -19.0\n",
      "\tep 349: reward: -21.0\n",
      "SAVED MODEL #350\n",
      "ep 350: reward: -20.0, mean reward: -20.139535\n",
      "\tep 351: reward: -20.0\n",
      "\tep 352: reward: -19.0\n",
      "\tep 353: reward: -21.0\n",
      "\tep 354: reward: -19.0\n",
      "\tep 355: reward: -21.0\n",
      "\tep 356: reward: -21.0\n",
      "\tep 357: reward: -21.0\n",
      "\tep 358: reward: -20.0\n",
      "\tep 359: reward: -19.0\n",
      "ep 360: reward: -17.0, mean reward: -20.105791\n",
      "\tep 361: reward: -20.0\n",
      "\tep 362: reward: -19.0\n",
      "\tep 363: reward: -21.0\n",
      "\tep 364: reward: -19.0\n",
      "\tep 365: reward: -19.0\n",
      "\tep 366: reward: -21.0\n",
      "\tep 367: reward: -21.0\n",
      "\tep 368: reward: -20.0\n",
      "\tep 369: reward: -20.0\n",
      "ep 370: reward: -20.0, mean reward: -20.096152\n",
      "\tep 371: reward: -20.0\n",
      "\tep 372: reward: -21.0\n",
      "\tep 373: reward: -21.0\n",
      "\tep 374: reward: -21.0\n",
      "\tep 375: reward: -20.0\n",
      "\tep 376: reward: -19.0\n",
      "\tep 377: reward: -21.0\n",
      "\tep 378: reward: -21.0\n",
      "\tep 379: reward: -21.0\n",
      "ep 380: reward: -20.0, mean reward: -20.134720\n",
      "\tep 381: reward: -21.0\n",
      "\tep 382: reward: -21.0\n",
      "\tep 383: reward: -19.0\n",
      "\tep 384: reward: -19.0\n",
      "\tep 385: reward: -21.0\n",
      "\tep 386: reward: -20.0\n",
      "\tep 387: reward: -19.0\n",
      "\tep 388: reward: -19.0\n",
      "\tep 389: reward: -21.0\n",
      "ep 390: reward: -20.0, mean reward: -20.121371\n",
      "\tep 391: reward: -20.0\n",
      "\tep 392: reward: -21.0\n",
      "\tep 393: reward: -19.0\n",
      "\tep 394: reward: -20.0\n",
      "\tep 395: reward: -20.0\n",
      "\tep 396: reward: -19.0\n",
      "\tep 397: reward: -20.0\n",
      "\tep 398: reward: -19.0\n",
      "\tep 399: reward: -21.0\n",
      "SAVED MODEL #400\n",
      "ep 400: reward: -19.0, mean reward: -20.090166\n",
      "\tep 401: reward: -21.0\n",
      "\tep 402: reward: -21.0\n",
      "\tep 403: reward: -21.0\n",
      "\tep 404: reward: -20.0\n",
      "\tep 405: reward: -20.0\n",
      "\tep 406: reward: -21.0\n",
      "\tep 407: reward: -21.0\n",
      "\tep 408: reward: -21.0\n",
      "\tep 409: reward: -21.0\n",
      "ep 410: reward: -21.0, mean reward: -20.158237\n",
      "\tep 411: reward: -20.0\n",
      "\tep 412: reward: -20.0\n",
      "\tep 413: reward: -21.0\n",
      "\tep 414: reward: -20.0\n",
      "\tep 415: reward: -21.0\n",
      "\tep 416: reward: -20.0\n",
      "\tep 417: reward: -20.0\n",
      "\tep 418: reward: -21.0\n",
      "\tep 419: reward: -21.0\n",
      "ep 420: reward: -21.0, mean reward: -20.191639\n",
      "\tep 421: reward: -21.0\n",
      "\tep 422: reward: -20.0\n",
      "\tep 423: reward: -21.0\n",
      "\tep 424: reward: -19.0\n",
      "\tep 425: reward: -21.0\n",
      "\tep 426: reward: -21.0\n",
      "\tep 427: reward: -21.0\n",
      "\tep 428: reward: -20.0\n",
      "\tep 429: reward: -21.0\n",
      "ep 430: reward: -20.0, mean reward: -20.221074\n",
      "\tep 431: reward: -21.0\n",
      "\tep 432: reward: -21.0\n",
      "\tep 433: reward: -21.0\n",
      "\tep 434: reward: -21.0\n",
      "\tep 435: reward: -20.0\n",
      "\tep 436: reward: -20.0\n",
      "\tep 437: reward: -21.0\n",
      "\tep 438: reward: -19.0\n",
      "\tep 439: reward: -20.0\n",
      "ep 440: reward: -19.0, mean reward: -20.226936\n",
      "\tep 441: reward: -20.0\n",
      "\tep 442: reward: -21.0\n",
      "\tep 443: reward: -20.0\n",
      "\tep 444: reward: -21.0\n",
      "\tep 445: reward: -20.0\n",
      "\tep 446: reward: -21.0\n",
      "\tep 447: reward: -20.0\n",
      "\tep 448: reward: -21.0\n",
      "\tep 449: reward: -21.0\n",
      "SAVED MODEL #450\n",
      "ep 450: reward: -20.0, mean reward: -20.253186\n",
      "\tep 451: reward: -20.0\n",
      "\tep 452: reward: -21.0\n",
      "\tep 453: reward: -21.0\n",
      "\tep 454: reward: -20.0\n",
      "\tep 455: reward: -20.0\n",
      "\tep 456: reward: -20.0\n",
      "\tep 457: reward: -21.0\n",
      "\tep 458: reward: -21.0\n",
      "\tep 459: reward: -21.0\n",
      "ep 460: reward: -20.0, mean reward: -20.276929\n",
      "\tep 461: reward: -21.0\n",
      "\tep 462: reward: -21.0\n",
      "\tep 463: reward: -20.0\n",
      "\tep 464: reward: -20.0\n",
      "\tep 465: reward: -21.0\n",
      "\tep 466: reward: -21.0\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "while not done and n < num_episodes:\n",
    "    # Preprocess the observation\n",
    "    cur_x = preprocess(obs)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(n_size*n_size)\n",
    "    prev_x = cur_x\n",
    "\n",
    "    # Predict the action\n",
    "    aprob = agent.predict_UP(x); aprob = aprob[0,:]\n",
    "    action = np.random.choice(n_actions, p=aprob)\n",
    "#     print(action)\n",
    "    label = np.zeros_like(aprob) ; label[action] = 1\n",
    "\n",
    "    # Step the environment and get new measurements\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    reward_sum += reward\n",
    "\n",
    "    # record game history\n",
    "    xs.append(x) ; ys.append(label) ; rs.append(reward)\n",
    "\n",
    "    if done:\n",
    "        # update running reward\n",
    "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "        running_rewards.append(running_reward)\n",
    "        feed = {agent.tf_x: np.vstack(xs), \n",
    "                agent.tf_epr: np.vstack(rs), \n",
    "                agent.tf_y: np.vstack(ys)}\n",
    "        # print progress console\n",
    "        if n % 10 == 0:\n",
    "            print('ep {}: reward: {}, mean reward: {:3f}'.format(n, reward_sum, running_reward))\n",
    "        else:\n",
    "            print('\\tep {}: reward: {}'.format(n, reward_sum))\n",
    "\n",
    "        # Start next episode and save model\n",
    "        xs, rs, ys = [], [], []\n",
    "        obs = env.reset()\n",
    "        n += 1 # the Next Episode\n",
    "\n",
    "        reward_sum = 0\n",
    "        if n% 50 == 0:\n",
    "            agent.save()\n",
    "        done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(running_rewards)\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('Running Average')\n",
    "plt.show()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
